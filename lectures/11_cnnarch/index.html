
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.5.1">
    
    
      
        <title>CNNs Popular Architectures - ErSE 222 - Machine Learning in Geoscience</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.2e8b5541.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#009485">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="teal" data-md-color-accent="teal">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cnns-popular-architectures" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ErSE 222 - Machine Learning in Geoscience" class="md-header__button md-logo" aria-label="ErSE 222 - Machine Learning in Geoscience" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ErSE 222 - Machine Learning in Geoscience
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              CNNs Popular Architectures
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ErSE 222 - Machine Learning in Geoscience" class="md-nav__button md-logo" aria-label="ErSE 222 - Machine Learning in Geoscience" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    ErSE 222 - Machine Learning in Geoscience
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Homepage
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../gradind/" class="md-nav__link">
        Grading system
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../schedule/" class="md-nav__link">
        Schedule
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Lectures
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Lectures" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Lectures
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../01_intro/" class="md-nav__link">
        Introduction to Machine Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_linalg/" class="md-nav__link">
        Linear Algebra refresher
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../02_prob/" class="md-nav__link">
        Probability refresher
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../03_gradopt/" class="md-nav__link">
        Gradient-based optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../04_linreg/" class="md-nav__link">
        Linear and Logistic Regression
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../05_nn/" class="md-nav__link">
        Basics of Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../06_nn/" class="md-nav__link">
        More on Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../07_bestpractice/" class="md-nav__link">
        Best practices in the training of Machine Learning models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../08_gradopt1/" class="md-nav__link">
        More on gradient-based optimization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../09_mdn/" class="md-nav__link">
        Uncertainty Quantification in Neural Networks and Mixture Density Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../10_cnn/" class="md-nav__link">
        Convolutional Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          CNNs Popular Architectures
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        CNNs Popular Architectures
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lenet-5" class="md-nav__link">
    LeNet-5
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    AlexNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vgg-16" class="md-nav__link">
    VGG-16
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#googlelenet-and-inception" class="md-nav__link">
    GoogleLeNet and Inception
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    ResNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unet" class="md-nav__link">
    UNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-readings" class="md-nav__link">
    Additional readings
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../12_seqmod/" class="md-nav__link">
        Sequence modelling
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../13_dimred/" class="md-nav__link">
        Dimensionality reduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../14_vae/" class="md-nav__link">
        Generative Modelling and Variational AutoEncoders
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../15_gans/" class="md-nav__link">
        Generative Adversarial Networks (GANs)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../16_pinns/" class="md-nav__link">
        Scientific Machine Learning and Physics-informed Neural Networks
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../17_deepinv/" class="md-nav__link">
        Deep learning for Inverse Problems
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lenet-5" class="md-nav__link">
    LeNet-5
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    AlexNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vgg-16" class="md-nav__link">
    VGG-16
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#googlelenet-and-inception" class="md-nav__link">
    GoogleLeNet and Inception
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    ResNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unet" class="md-nav__link">
    UNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-readings" class="md-nav__link">
    Additional readings
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="cnns-popular-architectures">CNNs Popular Architectures</h1>
<p>This lecture provides an overview of how deep learning, especially in the context of CNNs (and computer vision in general), has
evolved over the last decade. This is something that it is good to be familiar with because:</p>
<ul>
<li>whilst most of these advances are given for granted and routinely used today, it is always insightful to learn <em>how</em> ans <em>why</em> these
  developments were made;</li>
<li>we can use architectures that worked well with no (or minimal) adaptation to our problem at hand (we will see that this is very commonly 
  done with high degree of success in geoscience);</li>
<li>even better, sometimes we can decide to use pre-trained networks and fine-tune them with limited amount of label data. In this case knowing
  the network architecture in details allows us to make informed choices, such as remove some of the final layers and introduce new ones that 
  better adapt to the problem at hand (e.g., different number of classes).</li>
</ul>
<h2 id="lenet-5">LeNet-5</h2>
<p>One of the first successful CNNs was created and trained by the famous Yan Le Cun in 1989 with the objective of classifying hand-written digits. 
As we will see when comparing this to other popular networks, the size of LeNet-5 is very limited, mostly due to the hardware capabilities at that time (and the availability of a fairly small training
dataset). </p>
<p>As shown in the figure below, this network is composed of:</p>
<ul>
<li>2 convolutional layers with filter size equal to $5 \times <span class="arithmatex">\(5\)</span>, stride equal to 1, and number of channels equal to 6 and 16, respectively;</li>
<li>2 average pooling layers that reduce the height and width of the feature maps by a factor of 2;</li>
<li>3 fully connected layers of size 120, 84, and 10 (the number of digits to classify);</li>
<li>softmax activation in the final layer;</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 60k\)</span>. Finally, looking at the network architecture two things stand out that probably
today would have been implemented differently:</p>
<ul>
<li>average pool layers are not so popular today, max pool layers are more commonly used;</li>
<li>activations were used also after pooling and all activations where sigmoid/tangent. Again, today ReLU or one of its variant is more commonly
  used and no activations are added after pooling layers.</li>
</ul>
<p><img alt="LENET" src="../figs/letnet.png" /></p>
<h2 id="alexnet">AlexNet</h2>
<p>AlexNet represents a milestone in the field of DeepLearning. Developed by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton, this network
was the first CNN that won the popular computer vision competition ImageNet. Not only that, but the network outperformed other submissions by
far, and brought Deep Learning to the attention of the larger Computer Vision community.</p>
<p>As shown in the figure below, this network is not very different from LeNet-5 in its individual components, it is however much deeper and contains
much more trainable parameters. More specifically, it is composed of:</p>
<ul>
<li>5 convolutional layers with variable filter size (ranging from <span class="arithmatex">\(11 \times 11\)</span> in the first layer all the way to <span class="arithmatex">\(3 \times 3\)</span> in some of the deeper layers);</li>
<li>3 max pooling layers that reduce the height and width of the feature maps by a factor of 2;</li>
<li>3 fully connected layers of size 4096, 4096, and 1000 (the number of digits to classify);</li>
<li>softmax activation in the final layer;</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 60M\)</span>, 3 order of magnitude more than that of LeNet-5. A number of interesting feature of this
network:</p>
<ul>
<li>the number of channels in the different layers: initially, this grows from 3 (i.e., RGB) to 384 and it is then reduced
to 256 all the way to the FC layer;</li>
<li>ReLU is used as activation function for all hidden layers;</li>
<li>Dropout is used to avoid overfitting;</li>
</ul>
<p><img alt="ALEXNET" src="../figs/alexnet.png" /></p>
<h2 id="vgg-16">VGG-16</h2>
<p>In 2015, the Visual Geometry Group at Oxford introduce a new CNN architecture called VGG. The key architectural change here is the fact that 
the network was much deeper than most state-of-the art networks at that time (16 layers); this was achieved by trading filter size (now <span class="arithmatex">\(3 \times 3\)</span>) 
for depth. Moreover, whilst other networks like AlexNet were hand-crafted with very different filter sizes, strides and padding from layer to layer,
this network is really very simple to define:</p>
<ul>
<li>16 <span class="arithmatex">\(3 \times 3\)</span> convolutional layers with stride equal to 1;</li>
<li>16 max pooling laywrs with filter size and stride equal to 2.</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 138M\)</span>, roughly twice more than those of AlexNet.</p>
<p>The key insight of VGG, which we will see is also used in later CNN architectures, is that stacks of convolutional layers with small filters
can emulate the receptive field of one layer with larger filter sizes. Note that further extensions of VGG-16 have been proposed, for example
VGG-19 where the network is composed of 19 layers.</p>
<p><img alt="VGG16" src="../figs/vgg16.png" /></p>
<h2 id="googlelenet-and-inception">GoogleLeNet and Inception</h2>
<p>In 2014, Christian Szegedy from Google was working on reducing the computational burden of deep neural networks. At that time, a new convolutional
block was introduced under the name of Inception Layer:</p>
<p><img alt="INCEPTION" src="../figs/inception.png" /></p>
<p>Instead of choosing the size of the bank of filters to be used upfront, the inception layer uses more than once filter size at the same time (a kind of multi-resolution approach).
More specifically the input is sent into 4 paths in parallel:</p>
<ul>
<li><span class="arithmatex">\(1 \times 1\)</span> convolution block;</li>
<li><span class="arithmatex">\(3 \times 3\)</span> convolution block;</li>
<li><span class="arithmatex">\(5 \times 5\)</span> convolution block;</li>
<li>Max pooling block.</li>
</ul>
<p>Moreover, since sending an input with large width, height, and channel number into a <span class="arithmatex">\(3 \times 3\)</span> (or <span class="arithmatex">\(5 \times 5\)</span>) convolutional layer would result in a very large 
number of trainable parameters and extreme computational cost, the input is first sent into a <span class="arithmatex">\(1 \times 1\)</span> that reduces the channel size and then the channel size is increased
again in the next layer. The <span class="arithmatex">\(1 \times 1\)</span> layers act as a <em>bottleneck layer</em> keeping the number of trainable parameters low.  Similarly, after the max pooling layer the number of channels is controlled via another <span class="arithmatex">\(1 \times 1\)</span> convolutional layer. The four
outputs are simply concatenated together to form the output of the Inception layer.</p>
<p>The GoogleLeNet network is a large networks where multiple of these Inception layers are stacked together. This network presents an additional set of new features:</p>
<ul>
<li>two <em>side branches</em> are added at different stages of the network, where intermediate representations from hidden layers are passed through a few more
  layers and sent to a classifier. These classifiers perform the same task of the main classifier placed at the end of the network and have been shown
  to act as a natural regularizer, ensuring that the hidden features are as expressive as possible to the point they can be used directly for the classification
  task at hand.</li>
</ul>
<p><img alt="GLENET" src="../figs/googlelenet.png" /></p>
<h2 id="resnet">ResNet</h2>
<p>We can already observe a trend moving from LeNet-5 to VGG-19. From the 80' all the way to the early 2000', networks started to become deeper and deeper.
However, despite deeper network can generally achieve better performance, practitioners started to also experience painfully slow training. It was later discovered
that this was caused by the vanishing gradient problem.</p>
<p>Around the same time of VGG-16, He and coauthors proposed a new network block called the Residual Block. As already discussed in our last lecture,
this block introduces the innovative idea of shortcuting some of the activations forward in the computational graph and summing them to the activations
of the main path. This gave rise to the so-called ResNet that proved to be much easier (and faster) to train than other CNNs when stacking a large number of layers,
even up to 100 (or 1000) of layers!</p>
<p><img alt="RESNET" src="../figs/resnet.png" /></p>
<p>The figure above shows ResNet-18, but it is important to remember that the idea of adding skip-connections every couple of layers has much wider 
implications than just for the ResNet architecture. One of the key benefits introduced by ResNet is the ability to increase the depth of a network without
incurring in the risk of overfitting the training data. So, whilst in theory deeper networks should always reduce the training error, this is not always the case
for plain networks. On the other hand, networks with Residual blocks are much more successful in that respect.</p>
<p><img alt="RESNETTRAINING" src="../figs/resnettraining.png" /></p>
<h2 id="unet">UNet</h2>
<p>The UNet architecture was proposed by Ronneberger et al. in 2015 in the context of interpretation of microscopy images. 
This network architecture presents however a number of innovative design choices which led to its widespread use in a variety of disciplines
for both semantic segmentation and regression tasks.</p>
<p>More specifically, whilst most of the networks we have discussed so far are specifically designed for classification
tasks where inputs are of much larger size of target (i.e., imagine taking images from the MNIST dataset as input as a single vector of 10 elements as output),
UNet was originally conceived for a <em>semantic segmentation</em> task. Semantic segmentation is a special case of classification where 
instead of predicting a class per input samples, we want to predict a class for each element of that sample. This makes the output space very large,
equal to that of the input times the number of classes.</p>
<p><img alt="SEMSEG" src="../figs/semseg.png" /></p>
<p>The UNet architecture presents the following characteristics:</p>
<ul>
<li>it can be seen as composed by two networks, an <em>Encoder</em> or contracting path, and a <em>Decoder</em> or expanding path. This is a common
  design in dimensionality reduction networks like AutoEncoders (see <a href="14_autoencoder.md">Lecture X</a> for more details). Each level of the encoder 
  network contains a number of convolutional layers followed by a downsampler (usually achieved by means of max pooling). On the other hand,
  the decoder is composed of convolutional layers preceded by an upsampler (this can be either an interpolator like a bilinear interpolation or
  a convtranspose layer);</li>
<li>skip connections are introduced at each level of the contracting path, taking those features all the way to the corresponding level of the
  expanding path (where they are concatenated with the features coming from a deeper level of the contracting path itself). Whilst we have
  already discussed the importance of skip connections for stable training, here these skip connections are brought to a new level, as a very 
  large portion of the network is skipped and concatenation is used instead of summation. The presence of such connections make the UNet architecture
  able to create very high resolution segmentation and regression outputs;</li>
</ul>
<p>Finally, restricting ourselves to geoscience applications, UNet has been successfully used for a variety of tasks such as:</p>
<ul>
<li>Salt body / channel / karst extraction from seismic data (semantic segmentation);</li>
<li>Fault and horizon tracking (semantic segmentation, where a skeletonized fault or horizon volume is used as the target to predict);</li>
<li>Microseismic event detection (semantic segmentation);</li>
<li>Seismic data interpolation, denoising, deghosting (regression, or more precisely <em>domain translation</em>);</li>
<li>and more...</li>
</ul>
<p><img alt="UNET" src="../figs/unet.png" /></p>
<p>To conclude a summary of some of the most popular CNN architectures used for various computer vision task is shown in the figure below. Note
the size of the circles refer to the number of trainable parameters of the associated network.</p>
<p><img alt="ARCHITS" src="../figs/archits.png" /></p>
<h2 id="additional-readings">Additional readings</h2>
<ul>
<li>the following <a href="https://towardsdatascience.com/neural-network-architectures-156e5bad51ba">blog post</a> provides a good overview of some of
  the most popular architectures in computer vision, including those discussed in this lecture.</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../10_cnn/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Convolutional Neural Networks" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Convolutional Neural Networks
            </div>
          </div>
        </a>
      
      
        
        <a href="../12_seqmod/" class="md-footer__link md-footer__link--next" aria-label="Next: Sequence modelling" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Sequence modelling
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.ecf98df9.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.d691e9de.min.js"></script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>