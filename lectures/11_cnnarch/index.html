
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.2.8">
    
    
      
        <title>Convolutional Neural Network Architectures - ErSE 222 - Machine Learning in Geoscience</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.cb6bc1d0.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.39b8e14a.min.css">
        
          
          
          <meta name="theme-color" content="#009485">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="teal" data-md-color-accent="teal">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#convolutional-neural-network-architectures" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../.." title="ErSE 222 - Machine Learning in Geoscience" class="md-header-nav__button md-logo" aria-label="ErSE 222 - Machine Learning in Geoscience">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      <div class="md-header-nav__ellipsis">
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            ErSE 222 - Machine Learning in Geoscience
          </span>
        </div>
        <div class="md-header-nav__topic">
          <span class="md-ellipsis">
            
              Convolutional Neural Network Architectures
            
          </span>
        </div>
      </div>
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ErSE 222 - Machine Learning in Geoscience" class="md-nav__button md-logo" aria-label="ErSE 222 - Machine Learning in Geoscience">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    ErSE 222 - Machine Learning in Geoscience
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Homepage
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../gradind/" class="md-nav__link">
        Grading system
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../schedule/" class="md-nav__link">
        Schedule
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
      
      <label class="md-nav__link" for="nav-4">
        Lectures
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Lectures" data-md-level="1">
        <label class="md-nav__title" for="nav-4">
          <span class="md-nav__icon md-icon"></span>
          Lectures
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../01_intro/" class="md-nav__link">
        Introduction to Machine Learning
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../02_linalg/" class="md-nav__link">
        Linear Algebra refresher
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../02_prob/" class="md-nav__link">
        Probability refresher
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../03_gradopt/" class="md-nav__link">
        Gradient-based optimization
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../04_linreg/" class="md-nav__link">
        Linear and Logistic Regression
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../05_nn/" class="md-nav__link">
        Basics of Neural Networks
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../06_nn/" class="md-nav__link">
        More on Neural Networks
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../07_bestpractice/" class="md-nav__link">
        Best practices in the training of Machine Learning models
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../08_gradopt1/" class="md-nav__link">
        More on gradient-based optimization
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../09_mdn/" class="md-nav__link">
        Uncertainty Quantification in Neural Networks and Mixture Density Networks
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../10_cnn/" class="md-nav__link">
        Convolutional Neural Networks
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Convolutional Neural Network Architectures
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Convolutional Neural Network Architectures
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lenet-5" class="md-nav__link">
    LeNet-5
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    AlexNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vgg-16" class="md-nav__link">
    VGG-16
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#googlelenet-and-inception" class="md-nav__link">
    GoogleLeNet and Inception
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    ResNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unet" class="md-nav__link">
    UNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-readings" class="md-nav__link">
    Additional readings
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../11_vae/" class="md-nav__link">
        VAE
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../12_gan/" class="md-nav__link">
        GANs
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../4_autoencoder/" class="md-nav__link">
        Autoencoders
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../4_pca/" class="md-nav__link">
        PCA
      </a>
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#lenet-5" class="md-nav__link">
    LeNet-5
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#alexnet" class="md-nav__link">
    AlexNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#vgg-16" class="md-nav__link">
    VGG-16
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#googlelenet-and-inception" class="md-nav__link">
    GoogleLeNet and Inception
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#resnet" class="md-nav__link">
    ResNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unet" class="md-nav__link">
    UNet
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#additional-readings" class="md-nav__link">
    Additional readings
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="convolutional-neural-network-architectures">Convolutional Neural Network Architectures</h1>
<p>This lecture provides an overview of how deep learning, especially in the context of CNNs (and computer vision in general), has
evolved over the last decade. This is something that it is good to be familar with because:</p>
<ul>
<li>whilst most of these advances are given for granted and routinely used today, it is always insigthful to learn <em>how</em> ans <em>why</em> these
  developments were made;</li>
<li>we can use architectures that worked well with no (or minimal) adaptation to our problem at hand (we will see that this is very commonly 
  done with high degree of success in geoscience);</li>
<li>even better, sometimes we can decide to use pre-trained networks and fine-tune them with limited amount of label data. In this case knowning
  the network architecture in details allows us to make informed choices, such as remove some of the final layers and introduce new ones that 
  better adapt to the problem at hand (e.g., different number of classes).</li>
</ul>
<h2 id="lenet-5">LeNet-5</h2>
<p>One of the first successful CNNs was created and trained by the famous Yan Le Cun in 1989 with the objective of classifying hand-written digits. 
As we will see when comparing this to other popular networks, the size of LeNet-5 is very limited, mostly due to the hardware capabilities at that time (and the availability of a fairly small training
dataset). </p>
<p>As shown in the figure below, this network is composed of:</p>
<ul>
<li>2 convolutional layers with filter size equal to $5 \times <span class="arithmatex">\(5\)</span>, stride equal to 1, and number of channels equal to 6 and 16, respectively;</li>
<li>2 average pooling layers that reduce the height and width of the feature maps by a factor of 2;</li>
<li>3 fully connected layers of size 120, 84, and 10 (the number of digits to classify);</li>
<li>softmax activation in the final layer;</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 60k\)</span>. Finally, looking at the network architecture two things stand out that probably
today would have been implemented differently:</p>
<ul>
<li>average pool layers are not so popular today, max pool layers are more commonly used;</li>
<li>activations were used also after pooling and all activations where sigmoid/tangent. Again, today ReLU or one of its variant is more commonly
  used and no activations are added after pooling layers.</li>
</ul>
<p><img alt="LENET" src="../figs/letnet.png" /></p>
<h2 id="alexnet">AlexNet</h2>
<p>AlexNet represents a milestone in the field of DeepLearning. Developed by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton, this network
was the first CNN that won the popular computer vision competition ImageNet. Not only that, but the network outperformed other submissions by
far, and brough Deep Learning to the attention of the larger Computer Vision community.</p>
<p>As shown in the figure below, this network is not very different from LeNet-5 in its individual components, it is however much deeper and contains
much more trainable parameters. More specifically, it is composed of:</p>
<ul>
<li>5 convolutional layers with variable filter size (ranging from <span class="arithmatex">\(11 \times 11\)</span> in the first layer all the way to <span class="arithmatex">\(3 \times 3\)</span> in some of the deeper layers);</li>
<li>3 max pooling layers that reduce the height and width of the feature maps by a factor of 2;</li>
<li>3 fully connected layers of size 4096, 4096, and 1000 (the number of digits to classify);</li>
<li>softmax activation in the final layer;</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 60M\)</span>, 3 order of magnitude more than that of LeNet-5. A number of interesting feature of this
network:</p>
<ul>
<li>the number of channels in the different layers: initially, this grows from 3 (i.e., RGB) to 384 and it is then reduced
to 256 all the way to the FC layer;</li>
<li>ReLU is used as activation function for all hidden layers;</li>
<li>Dropout is used to avoid overfitting;</li>
</ul>
<p><img alt="ALEXNET" src="../figs/alexnet.png" /></p>
<h2 id="vgg-16">VGG-16</h2>
<p>In 2015, the Visual Geometry Group at Oxford introduce a new CNN architecture called VGG. The key architectural change here is the fact that 
the network was much deeper than most state-of-the art networks at that time (16 layers); this was achieved by trading filter size (now <span class="arithmatex">\(3 \times 3\)</span>) 
for depth. Moreover, whilst other networks like AlexNet were hand-crafted with very different filter sizes, strides and padding from layer to layer,
this network is really very simple to define:</p>
<ul>
<li>16 <span class="arithmatex">\(3 \times 3\)</span> convolutional layers with stride equal to 1;</li>
<li>16 max pooling laywrs with filter size and stride equal to 2.</li>
</ul>
<p>and the overall number of training parameters is <span class="arithmatex">\(\approx 138M\)</span>, roughly twice more than those of AlexNet.</p>
<p>The key insight of VGG, which we will see is also used in later CNN architectures, is that stacks of convolutional layers with small filters
can emulate the receptive field of one layer with larger filter sizes. Note that further extensions of VGG-16 have been proposed, for example
VGG-19 where the network is composed of 19 layers.</p>
<p><img alt="VGG16" src="../figs/vgg16.png" /></p>
<h2 id="googlelenet-and-inception">GoogleLeNet and Inception</h2>
<p>In 2014, Christian Szegedy from Google was working on reducing the computational burden of deep neural networks. At that time, a new convolutional
block was introduced under the name of Inception Layer:</p>
<p><img alt="INCEPTION" src="../figs/inception.png" /></p>
<p>Instead of choosing the size of the bank of filters to be used upfront, the inception layer uses more than once filter size at the same time (a kind of multi-resolution approach).
More specifically the input is sent into 4 paths in parallel:</p>
<ul>
<li><span class="arithmatex">\(1 \times 1\)</span> convolution block;</li>
<li><span class="arithmatex">\(3 \times 3\)</span> convolution block;</li>
<li><span class="arithmatex">\(5 \times 5\)</span> convolution block;</li>
<li>Max pooling block.</li>
</ul>
<p>Moreover, since sending an input with large width, height, and channel number into a <span class="arithmatex">\(3 \times 3\)</span> (or <span class="arithmatex">\(5 \times 5\)</span>) convolutional layer would result in a very large 
number of trainable parameters and extreme computational cost, the input is first sent into a <span class="arithmatex">\(1 \times 1\)</span> that reduces the channel size and then the channel size is increased
again in the next layer. The <span class="arithmatex">\(1 \times 1\)</span> layers act as a <em>bottleneck layer</em> keeping the number of trainable parameters low.  Similarly, after the max pooling layer the number of channels is controlled via another <span class="arithmatex">\(1 \times 1\)</span> convolutional layer. The four
outputs are simply concatenated together to form the output of the Inception layer.</p>
<p>The GoogleLeNet network is a large networks where multiple of these Inception layers are stacked together. This network presents an additional set of new features:</p>
<ul>
<li>two <em>side branches</em> are added at different stages of the network, where intermediate representations from hidden layers are passed through a few more
  layers and sent to a classifier. These classifiers perform the same task of the main classifier placed at the end of the network and have been shown
  to act as a natural regularizer, ensuring that the hidden features are as expressive as possible to the point they can be used directly for the classification
  task at hand.</li>
</ul>
<p><img alt="GLENET" src="../figs/googlelenet.png" /></p>
<h2 id="resnet">ResNet</h2>
<p>We can already observe a trend moving from LeNet-5 to VGG-19. From the 80' all the way to the early 2000', networks started to become depeer and deeper.
However, despite deeper network can generally achieve better performance, practitioners started to also experience painfully slow training. It was later discovered
that this was caused by the vanishing gradient problem.</p>
<p>Around the same time of VGG-16, He and coauthors proposed a new network block called the Residual Block. As already discussed in our last lecture,
this block introduces the innovative idea of shortcutting some of the activations forward in the computational graph and summing them to the activations
of the main path. This gave rise to the so-called ResNet that proved to be much easier (and faster) to train than other CNNs when stacking a large number of layers,
even up to 100 (or 1000) of layers!</p>
<p><img alt="RESNET" src="../figs/resnet.png" /></p>
<p>The figure above shows ResNet-18, but it is important to remember that the idea of adding skip-connections every couple of layers has much wider 
implications than just for the ResNet architecture. One of the key benefits introduced by ResNet is the ability to increase the depth of a network without
incurring in the risk of overfitting the training data. So, whilst in theory deeper networks should always reduce the training error, this is not always the case
for plain networks. On the other hand, networks with Residual blocks are much more succesfull in that respect.</p>
<p><img alt="RESNETTRAINING" src="../figs/resnettraining.png" /></p>
<h2 id="unet">UNet</h2>
<p>Bla bla..</p>
<p>To conclude a summary of some of the most popular CNN architectures used for various computer vision task is shown in the figure below. Note
the size of the circles refer to the number of trainable parameters of the associated network.</p>
<p><img alt="ARCHITS" src="../figs/archits.png" /></p>
<h2 id="additional-readings">Additional readings</h2>
<ul>
<li>the following <a href="https://towardsdatascience.com/neural-network-architectures-156e5bad51ba">blog post</a> provides a good overview of some of
  the most popular architectures in computer vision, including those discussed in this lecture.</li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../10_cnn/" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Convolutional Neural Networks
              </div>
            </div>
          </a>
        
        
          <a href="../11_vae/" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                VAE
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/vendor.18f0862e.min.js"></script>
      <script src="../../assets/javascripts/bundle.994580cf.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "../..",
          features: [],
          search: Object.assign({
            worker: "../../assets/javascripts/worker/search.9c0e82ba.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>